% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scrape_weather.R
\name{scrape_weather}
\alias{scrape_weather}
\alias{scrape_burst_dk}
\alias{scrape_burst_eu}
\alias{scrape_continual}
\title{Scrape weather data for multiple locations (USE ONLY ONCE PER DAY, AND NEVER FROM INSIDE KU OR WHILE CONNECTED TO THE KU VPN)}
\usage{
scrape_burst_dk(year, path = "~/weather_scrape")

scrape_burst_eu(year, path = "~/weather_scrape")

scrape_continual(year, path = "~/weather_scrape")

scrape_weather(
  year,
  week,
  start_date,
  end_date,
  locations = NULL,
  path = "~/weather_scrape",
  max_scrapes = 60L,
  interval = "15s",
  fail_interval = "abort",
  progress = c("pb", "log", "none")
)
}
\arguments{
\item{year}{a single year providing a date range from 1st January to 31st December (inclusive), unless week is also specified (see below)}

\item{path}{a path to a folder to save results}

\item{week}{a single or range of weeks (ISO 8601, i.e. \%V) to fetch - note that week 1 and/or 52/53 may contain dates outside the year (NOT CURRENTLY USED)}

\item{start_date}{start date for the relevant period (inclusive; NOT CURRENTLY USED)}

\item{end_date}{end date for the relevant period (inclusive; NOT CURRENTLY USED)}

\item{locations}{a data frame of locations to scrape (optional - otherwise \code{\link{weather_locations}} is used)}

\item{max_scrapes}{the maximum number of scrapes to run}

\item{interval}{the interval between scrapes (should end in s, m or h)}

\item{fail_interval}{a pause interval following an unsuccessful scrape (should end in s, m or h)}

\item{progress}{the type of progress update to show - either "pb", "log" or "none"}
}
\value{
a data frame showing the scraping status of each location, invisibly
}
\description{
Scrape weather data for multiple locations (USE ONLY ONCE PER DAY, AND NEVER FROM INSIDE KU OR WHILE CONNECTED TO THE KU VPN)
}
\details{
NOTE:  DO NOT USE THESE FUNCTIONS FROM INSIDE A KU NETWORK OR WHILE
CONNECTED TO THE KU VPN.  ALSO MAKE SURE YOU ONLY START A SINGLE SCRAPE
FROM WITHIN YOUR OWN NETWORK PER DAY!!!

The OpenMeto fair usage policy (https://open-meteo.com/en/terms) allows us
to make 10000 API calls per day and/or 5000 per day and/or 600 per minute.
Scraping a full year of data for a single location is just under 60 API calls.
This equates to 15 minute intervals for continuous running (5760 API calls
per day), or a maximum of 60 locations with 15 second delays (3600 API calls
in around 15 mins). Note: some safety is deliberately built in to these
limits - please do not go over them!

This means you can either start the scrape_continual function and leave it
running continuously, or run the scrape_burst_dk or scrape_burst_eu functions
intermittently BUT A MAXIMUM OF ONCE PER DAY.

Note that API limits are shared by everyone on your network, and any calls
to \code{\link{fetch_weather}} also count against this. If you are not sure
what this means then please ask Matt before using the functions.
}
