% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scrape_weather.R
\name{scrape_weather}
\alias{scrape_weather}
\alias{scrape_burst_dk}
\alias{scrape_burst_eu}
\alias{scrape_continual}
\title{Scrape weather data for multiple locations (DO NOT USE FROM INSIDE KU OR KU VPN)}
\usage{
scrape_burst_dk(year, path = "~/weather_scrape")

scrape_burst_eu(year, path = "~/weather_scrape")

scrape_continual(year, path = "~/weather_scrape")

scrape_weather(
  year,
  start_date = as_date(str_c(year, "-01-01")),
  end_date = as_date(str_c(year, "12-31")),
  locations = NULL,
  path = "~/weather_scrape",
  max_scrapes = 60L,
  interval = "15s",
  fail_interval = "abort",
  progress = c("pb", "log", "none")
)
}
\arguments{
\item{year}{a single year to fetch (ignored if start_date/end_date are changed)}

\item{path}{a path to a folder to save results}

\item{start_date}{start date for the relevant period (inclusive)}

\item{end_date}{end date for the relevant period (inclusive)}

\item{locations}{a data frame of locations to scrape (optional - otherwise \code{\link{weather_locations}} is used)}

\item{max_scrapes}{the maximum number of scrapes to run}

\item{interval}{the interval between scrapes (should end in s, m or h)}

\item{fail_interval}{a pause interval following an unsuccessful scrape (should end in s, m or h)}

\item{progress}{the type of progress update to show - either "pb", "log" or "none"}
}
\value{
a data frame showing the scraping status of each location, invisibly
}
\description{
Scrape weather data for multiple locations (DO NOT USE FROM INSIDE KU OR KU VPN)
}
\details{
NOTE:  DO NOT USE THESE FUNCTIONS FROM INSIDE A KU NETWORK OR WHILE CONNECTED TO THE VPN

The OpenMeto fair usage policy (https://open-meteo.com/en/terms) allows us
to make 10000 API calls per day and/or 5000 per day and/or 600 per minute.
Scraping a full year of data for a single location is just under 60 API calls.
This equates to 15 minute intervals for continuous running (5760 API calls
per day), or a maximum of 60 locations with 15 second delays (3600 API calls
in around 15 mins). Note: some safety is deliberately built in to these
limits - please do not go over them!

This means you can either start the scrape_continual function and leave it
running continuously, or run the scrape_burst_dk or scrape_burst_eu functions
intermittently BUT A MAXIMUM OF ONCE PER DAY.

Note that API limits are shared by everyone on your network, and any calls
to \code{\link{fetch_weather}} also count against this.
}
